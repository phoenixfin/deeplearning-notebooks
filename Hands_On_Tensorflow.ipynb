{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hands On Tensorflow",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMslzq2C68RIf37IAapNyNj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmO0jPGJYoGT"
      },
      "source": [
        "# **Menjadi Powerful dengan Tensorflow - Hands On**\n",
        "> ## Aditya Firman Ihsan\n",
        "[![Github](https://img.shields.io/badge/Visit-My%20Github-black.svg)](https://github.com/phoenixfin) [![contact](https://img.shields.io/badge/Email-Contact-crimson.svg)](mailto:adityaihsan@telkomuniversity.ac.id)\n",
        "\n",
        "---\n",
        "\n",
        "[![contact](https://img.shields.io/badge/TensorFlow%20-%23FF6F00.svg?&style=for-the-badge&logo=TensorFlow&logoColor=white)](https://www.tensorflow.org/)\n",
        "[![Generic badge](https://img.shields.io/badge/Data%20Science-Telkom%20University-red.svg)](https://telkomuniversity.ac.id/)\n",
        "[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n",
        "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/187F05TJCOX76_THbLGi3UzOIuUJU3p5Q?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKNTkY9USY8K"
      },
      "source": [
        "<img src=\"https://pngimage.net/wp-content/uploads/2018/06/logo-tel-u-png-6.png\" alt=\"drawing\" height=\"100\"/><img src=\"https://miro.medium.com/max/4928/1*-QTg-_71YF0SVshMEaKZ_g.png\" alt=\"drawing\" height=\"100\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EaHxhpLGyHA"
      },
      "source": [
        "# **ï·½**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yQukdPyHED4"
      },
      "source": [
        "Dalam notebook ini, akan dipaparkan secara general dari A-Z apa yang bisa dilakukan dengan Tensorflow, beserta beberapa teknik yang ada di dalamnya. Tentu banyak yang tidak tercakup di sini, sehingga bila tertarik untuk belajar lebih dalam terkait Tensorflow bisa langsung ke [dokumentasinya](tensorflow.org) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yinoB5Ne0jr8"
      },
      "source": [
        "## 0. Prepare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2E3-oRN03h_"
      },
      "source": [
        "### 0.1. Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv6ktB0eJcsI"
      },
      "source": [
        "Mula-mula di impor terlebih dahulu semua *libary* yang dibutuhkan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSYunO3cZ62N"
      },
      "source": [
        "import PIL # untuk mengolah gambar\n",
        "import random # untuk menghasilkan bilangan acak\n",
        "import datetime # untuk mengambil waktu saat ini\n",
        "import numpy as np # untuk kebutuhan numerik\n",
        "import pandas as pd # untuk mengolah data\n",
        "import matplotlib.pyplot as plt # untuk plotting\n",
        "\n",
        "import tensorflow as tf # yang utama nih\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds \n",
        "\n",
        "# setup dulu logger dari tf biar tidak terlalu banyak output\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJQE7tegy5FP"
      },
      "source": [
        "### 0.1. Helper Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8enG3s19wLy"
      },
      "source": [
        "Sebelum mulai, didefinisikan dulu beberapa fungsi bantuan. Tidak perlu paham ini buat apa, nanti ketika ketemu dengan pemanggilannya, baru terlihat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d7hu5oDzFqU"
      },
      "source": [
        "# untuk membagi data berdasarkan rasio\n",
        "def split(x, y, ratio=0.8):\n",
        "    split_index = round(ratio * len(x))\n",
        "    slice1 = x[:split_index], y[:split_index]\n",
        "    slice2 = x[split_index:], y[split_index:]\n",
        "    return slice1, slice2\n",
        "\n",
        "# untuk plotting metrik yang dihasilkan dari training\n",
        "def plot_metrics(history, metrics):\n",
        "    plt.title(\"Model Performance\")\n",
        "    for metric in metrics:\n",
        "        plt.plot(history.history[metric],label=metric)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# untuk mengonvers gambar agar siap masuk ke model\n",
        "def prepare_image(img, size, module=None):\n",
        "    img = tf.expand_dims(img, -1)\n",
        "    img = tf.repeat(img, 3, -1)\n",
        "    img = tf.image.resize(img, size)  \n",
        "    if module:\n",
        "        img = module.preprocess_input(img)\n",
        "    return img\n",
        "\n",
        "# untuk menampilkan banyak gambar\n",
        "def show_figures(images, preds, pairs=False):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    if pairs:\n",
        "        images, comp_images = images\n",
        "        for n, img in enumerate(comp_images):\n",
        "            plt.subplot(3,5,5+n+1)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(img)\n",
        "    for n, img in enumerate(images):\n",
        "        plt.subplot(3,5,n+1)\n",
        "        plt.title(f'Prediksi: {preds[n]}')\n",
        "        plt.axis('off')\n",
        "        plt.imshow(img)\n",
        "    plt.suptitle(\"Model predictions\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxo1PiZC06nN"
      },
      "source": [
        "### 0.2. Import Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYRbFPLYNEwP"
      },
      "source": [
        "Ada 3 data berbeda yang akan digunakan sepanjang notebook ini, yakni data numerik, data gambar, dan data teks. Masing-masing data akan dibagi menjadi triadik *training-validation-test* yang menjadi standar penggunaan data dalam suatu model *Machine Learning*. \n",
        "\n",
        "![](https://www.machinecurve.com/wp-content/uploads/2020/11/feed-3.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfmr3T4jkx8q"
      },
      "source": [
        "#### 0.2.1. Data Numerik (Titanic)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sulQBU5U09oH"
      },
      "source": [
        "titanic_file = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
        "titanic_df = pd.read_csv(titanic_file)\n",
        "\n",
        "# lihat dulu sebagian isinya\n",
        "titanic_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atT-lMBjkqYH"
      },
      "source": [
        "list_town = list(titanic_df['embark_town'].unique())\n",
        "list_class = list(titanic_df['class'].unique())\n",
        "\n",
        "# mengubah fitur kategorikal menjadi \"one-hot\"\n",
        "titanic_df[list_town] = pd.get_dummies(titanic_df['embark_town'])\n",
        "titanic_df[list_class] = pd.get_dummies(titanic_df['class'])\n",
        "\n",
        "features = titanic_df[list_town + list_class + ['age']]\n",
        "labels = titanic_df['survived']\n",
        "\n",
        "(x, y), (x_test, y_test) = split(features, labels, 0.9)\n",
        "(x_train, y_train), (x_val, y_val) = split(x, y)\n",
        "\n",
        "# lihat lagi hasilnya seperti apa\n",
        "x_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ0Q9b9Ak5lq"
      },
      "source": [
        "#### 0.2.2. Data Gambar (Tulisan tangan angka)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkInY-4Pzv19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "ce124e87-0160-48a7-f88b-0c95165c0bd0"
      },
      "source": [
        "(img_train, lab_train), (img_test, lab_test) = tf.keras.datasets.mnist.load_data()\n",
        "img_train = img_train / 255.0\n",
        "img_test = img_test / 255.0\n",
        "\n",
        "(img_train, lab_train), (img_val, lab_val) = split(img_train, lab_train)\n",
        "\n",
        "# overview datanya seperti apa\n",
        "print('Jumlah Data Training: ', len(img_train))\n",
        "print('Jumlah Data Validasi: ', len(img_val))\n",
        "print('Jumlah Data Test: ', len(img_test))\n",
        "print(\"Dimensi setiap data (h x w pixels): \", img_train[0].shape)\n",
        "\n",
        "# ambil sampel acak. Coba saja jalankan berkali-kali, hasilnya berbeda\n",
        "index = random.randint(0,len(img_train))\n",
        "print(\"\\nContoh gambar:\")\n",
        "plt.title(f'Gambar digit {lab_train[index]}')\n",
        "plt.imshow(img_train[index])"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jumlah Data Training:  48000\n",
            "Jumlah Data Validasi:  12000\n",
            "Jumlah Data Test:  10000\n",
            "Dimensi setiap data (h x w pixels):  (28, 28)\n",
            "\n",
            "Contoh gambar:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f67bf6b3050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHppV4Z7qp5L"
      },
      "source": [
        "#### 0.2.3. Data Text (Judul berita)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgOQINOmhOq7"
      },
      "source": [
        "text_file = tf.keras.utils.get_file(\"sarcasm.json\", \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json\")\n",
        "data = pd.read_json(text_file)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fqpzEyRqDtI"
      },
      "source": [
        "sentences = data['headline']\n",
        "classes = data['is_sarcastic']\n",
        "\n",
        "# membagi data menjadi triad train-val-test\n",
        "(snt_train, cls_train), (snt_test, cls_test) = split(sentences, classes)\n",
        "(snt_train, cls_train), (snt_val, cls_val) = split(snt_train, cls_train)\n",
        "\n",
        "# dicek dulu sebagian hasilnya\n",
        "for i in range(5):\n",
        "  lab = \"Sarkas!\" if cls_train[i] == 1 else \"Netral\"\n",
        "  print(f'\"{snt_train[i]}\" -- {lab}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvVIN7w0wSvT"
      },
      "source": [
        "Setelah ini, akan dilakukan beberapa proses pembuatan model sederhana dengan berbagai API yang berbeda. Tensorflow kurang lebih memiliki fleksibilitas dalam penggunaannya sperti berikut\n",
        "\n",
        "![](https://github.com/phoenixfin/deeplearning-notebooks/blob/main/fleksibilitas_tf.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzKT9uJxZQsO"
      },
      "source": [
        "## 1. High Level API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPuGCn_eOMtQ"
      },
      "source": [
        "Dalam High-Level API, kita hanya melihat bungkusnya Tensorflow saja, yang sudah siap pakai dan tinggal disesuaikan dengan kebutuhan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8NCAhaeZzyt"
      },
      "source": [
        "### 1.2. Estimators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaxjFmmYOdVj"
      },
      "source": [
        "![](https://codespeedy.com/wp-content/uploads/2020/06/Schematic-diagram-of-an-estimator.png)\n",
        "\n",
        "Estimator merupakan model yang sudah dibundel sehingga pengguna hanya cukup menyediakan fungsi input dan data, dan selebihnya semua tinggal jalan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fl_C5d6hEl3"
      },
      "source": [
        "# menyiapkan fungsi input. Dalam hal ini, tf.data API digunakan\n",
        "def train_input_fn():\n",
        "  titanic = tf.data.experimental.make_csv_dataset(\n",
        "      titanic_file, batch_size=32,\n",
        "      label_name=\"survived\")\n",
        "  titanic_batches = (\n",
        "      titanic.cache().repeat().shuffle(500)\n",
        "      .prefetch(tf.data.AUTOTUNE))\n",
        "  return titanic_batches\n",
        "\n",
        "# melihat 1 batch data isinya apa\n",
        "for data in train_input_fn().take(1):\n",
        "  for key in data[0]:\n",
        "    print(\"=>\", key)\n",
        "    print(data[0][key].numpy(),'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDOx6lZVoVB8"
      },
      "source": [
        "# mendefinisikan fitur-fitur yang akan dilibatkan di model\n",
        "age = tf.feature_column.numeric_column('age')\n",
        "cls = tf.feature_column.categorical_column_with_vocabulary_list('class', ['First', 'Second', 'Third']) \n",
        "embark = tf.feature_column.categorical_column_with_hash_bucket('embark_town', 32)\n",
        "\n",
        "# definisikan  modelnya\n",
        "model = tf.estimator.LinearClassifier(    \n",
        "    model_dir = './estimator_logs',\n",
        "    feature_columns=[embark, cls, age],\n",
        "    n_classes=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGaJKkmVBgo2"
      },
      "source": [
        "model = model.train(input_fn=train_input_fn, steps=100)\n",
        "result = model.evaluate(train_input_fn, steps=10)\n",
        "\n",
        "for key, value in result.items():\n",
        "  print(key, \":\", value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPLD8n4CLVi_"
      },
      "source": [
        "for pred in model.predict(train_input_fn):\n",
        "  for key, value in pred.items():\n",
        "    print(key, \":\", value)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE7xEXSdesNw"
      },
      "source": [
        "### 1.2. Keras Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWhmSFTPQva0"
      },
      "source": [
        "![](https://miro.medium.com/max/394/1*CNPWTqFeMeCFkLOWjJU9Vg.jpeg)\n",
        "\n",
        "Keras Sequential API digunakan untuk membangun model secara sederhana dengan cukup membuat daftar layer yang digunakan. Cara membangun modelnya ada dua:\n",
        "1. Dengan memasukkan langsung daftar layer sebagai argumen ketika membuat model. Sintaksnya adalah sebagai berikut \n",
        "```\n",
        "model = tf.keras.Sequential(layers_list)\n",
        "``` \n",
        "dengan `layers_list` merupakan daftar layers yang digunakan secara berurutan.\n",
        "\n",
        "2. Bisa juga dengan menambahkan layer satu per satu belakangan. Jadi kita definisikan dulu modelnya tanpa argumen\n",
        "```\n",
        "model = tf.keras.Sequential()\n",
        "``` \n",
        "dan kemudian, kita gunakan metode `add` seperti berikut\n",
        "```\n",
        "model.add(layer1)\n",
        "model.add(layer2)\n",
        "``` \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkBe5RDHv8nI"
      },
      "source": [
        "#### 1.2.1. Implementasi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVt6IMP7luX0"
      },
      "source": [
        "##### a. Regresi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZXO0ag2RUf-"
      },
      "source": [
        "Kita mulai dari data yang sederhana dulu. Dalam hal ini, dibangun data linier yang diberi gangguan "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8pR_ik5RJgI"
      },
      "source": [
        "x = np.arange(10)\n",
        "y_true = 3.21*x + 1.4\n",
        "y_noise = y_true + tf.random.uniform((10,), minval=-10., maxval=10.)\n",
        "plt.plot(x,y_noise, 'o')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3OQYUSnSeZ8"
      },
      "source": [
        "Selanjutnya, kita definisikan modelnya, cukup sebuah neural network dengan 1 layer output atau dikenal juga sebagai *Perceptron*\n",
        "\n",
        "![](https://miro.medium.com/max/645/1*YPguig_eDkgWi5cgvWiUBg.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9BPMTmQg42R"
      },
      "source": [
        "model = tf.keras.Sequential([tf.keras.layers.Dense(1)])\n",
        "model.compile(optimizer='sgd', loss='mse', metrics=['mse'])\n",
        "model.fit(x,y_noise, epochs=10)\n",
        "\n",
        "y_pred = model.predict(x)\n",
        "plt.plot(x,y_noise, 'o')\n",
        "plt.plot(x, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgS0jqN4R6kF"
      },
      "source": [
        "Sederhana bukan? Setelah ini kita coba lebih rumit dengan melaukan klasifikasi pada 3 data berbeda yang telah disiapkan sebelumnya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S27pg5A3pa-S"
      },
      "source": [
        "##### b. Klasifikasi (Numerik)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E90DCmL8S5sF"
      },
      "source": [
        "Langsung kita definisikan saja modelnya karena datanya sudah siap. Dalam hal ini, berhubung korelasi datanya belum tentu linier, kita gunakan neural network dengan 2 layer tersembunyi (disebut juga *Multi-Layer Perceptron*) dan fungsi \"aktivasi\" ReLU untuk memberi dia nonlinearitas\n",
        "\n",
        "![](https://raw.githubusercontent.com/ledell/sldm4-h2o/master/mlp_network.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUmxSwHUl7bo"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(8, activation='relu'),\n",
        "        tf.keras.layers.Dense(8, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "hist = model.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdbUkd_xxhzV"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\"=== Performance on Test Data: ===\")\n",
        "print(\"Loss:\", test_loss)\n",
        "print(\"Accuracy:\", test_acc, \"\\n\")\n",
        "\n",
        "plot_metrics(hist, ['accuracy'])\n",
        "\n",
        "print(\"\\n=== Some Test Samples: ===\")\n",
        "samples = random.sample(list(x_test.index), 5)\n",
        "preds = model.predict(x_test.loc[samples]) >= 0.5\n",
        "for i, idx in enumerate(samples):\n",
        "    print(\"Truth:\", y_test.loc[idx], \"| Predicted:\", int(preds[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x13dLK16lzdU"
      },
      "source": [
        "##### c. Klasifikasi (Gambar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmnwdevAZ381"
      },
      "source": [
        "Model yang akan digunakan masih berupa *Multi-Layer Perceptron*. Kali ini layer output diberi aktivasi *softmax* untuk mendapatkan probabilitas dari 10 kelas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skqORzvE3Egy"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "hist = model.fit(img_train, lab_train, batch_size=64, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBwdTJ4VzPup"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(img_test, lab_test)\n",
        "print(\"=== Performance on Test Data: ===\")\n",
        "print(\"Loss:\", test_loss)\n",
        "print(\"Accuracy:\", test_acc, \"\\n\")\n",
        "\n",
        "plot_metrics(hist, ['accuracy'])\n",
        "\n",
        "print(\"\\n=== Some Test Samples: ===\")\n",
        "samples = random.sample(img_test.tolist(), 5)\n",
        "preds = np.argmax(model.predict(samples),axis=1)\n",
        "show_figures(samples, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6_rBKYLdL9k"
      },
      "source": [
        "Kita juga bisa membuat model berbentuk konvolusional. Arsitektur model yang dikenal juga sebagai CNN (Convolutional Neural Network) ini, menggunakan filter untuk mendapatkan informasi yang lebih dalam dari suatu gambar. Filter ini kemudian menjadi parameter yang dioptimisasi selama training.\n",
        "\n",
        "Suatu layer konvolusional di CNN biasanya diikuti dengan layer untuk *downsampling* (memperkecil resolusi dari suatu gambar) dengan tujuan untuk memperingan serta untuk mendapatkan informasi yang lebih abstrak pada layer berikutnya. Layer downsampling yang umum digunakan adalah Maximum Pooling, yakni mengambil piksel maksimum dari suatu set piksel, sehingga ukuran mengecil tanpa kehilangan informasi terlalu banyak.\n",
        "\n",
        "Gambaran arsitektur CNN kurang lebih seperti berikut\n",
        "![](https://miro.medium.com/proxy/1*uAeANQIOQPqWZnnuH-VEyw.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEIRsxmHegg-"
      },
      "source": [
        "Pada gambar di atas, digunakan dua pasang layer konvolusional-pooling sebelum kemudian diratakan ke dense network. Untuk sekarang, kita coba bangun arsitektur yang lebih sederhana dengan cukup 1 pasang konvolusional-pooling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiwVNmHteRoQ"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Reshape((28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "hist = model.fit(img_train, lab_train, batch_size=64, epochs=5)\n",
        "plot_metrics(hist, ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UJZjpx0fWiC"
      },
      "source": [
        "Performanya tidak jauh berbeda dengan model dense network biasa. Hal ini dikarenakan memang data yang digunakan relatif kecil dan tidaklah kompleks. CNN akan terasa manfaatnya untuk klasifikasi atau proses training gambar yang lebih rumit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBh1Axqc1ob9"
      },
      "source": [
        "##### c. Klasifikasi (Text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJWFuRk6VuGZ"
      },
      "source": [
        "Khusus untuk data text, kita perlu kuantifikasi data tersebut agar bisa masuk ke model. Ada dua tahap untuk melakukan ini:\n",
        "- **Tokenisasi**, artnya mengonversi 1 kalimat utuh menjadi bagian-bagian yang diinginkan (biasanya per kata) dimana setiap bagian itu diwakilkan 1 token.\n",
        "- ***Embedding***, artinya memroyeksikan setiap token ke suatu vektor (array) n-dimensi agar bisa merepresentasikan posisi kata tersebut dan relasinya dengan kata lainnya.\n",
        "\n",
        "![](https://freecontent.manning.com/wp-content/uploads/Chollet_DLfT_01.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGKycKugd6Kz"
      },
      "source": [
        "prep = tf.keras.preprocessing\n",
        "\n",
        "# definisikan dulu pembuat tokennya\n",
        "tokenizer = prep.text.Tokenizer(num_words=1000, oov_token='<OOV>')\n",
        "# agar kemudian bisa disesuaikan dengan data trainng\n",
        "tokenizer.fit_on_texts(snt_train)\n",
        "\n",
        "seq_train = tokenizer.texts_to_sequences(snt_train)\n",
        "seq_val = tokenizer.texts_to_sequences(snt_val)\n",
        "seq_test = tokenizer.texts_to_sequences(snt_test)\n",
        "\n",
        "# kita lihat hasil tokennnya seperti apa\n",
        "seq_train[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7PYivHLrf4m"
      },
      "source": [
        "# kita lakukan hal yang sama setiap data (train-val-test)\n",
        "pad_train = prep.sequence.pad_sequences(seq_train, maxlen=50, padding='post', truncating='post')\n",
        "pad_val = prep.sequence.pad_sequences(seq_val, maxlen=50, padding='post', truncating='post')\n",
        "pad_test = prep.sequence.pad_sequences(seq_test, maxlen=50, padding='post', truncating='post')\n",
        "\n",
        "pad_train[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v870567X0UT"
      },
      "source": [
        "Model yang akan dipakai adalah model RNN (*Recurrent Neural Network*) dengan cell LSTM (*Long Short-Term Memory*) yang *Bidirectional*. Berhubung di luar bahasan dan tidak sederhana, maka tidak akan dibahas secara detail di sini.\n",
        "\n",
        "![](https://paperswithcode.com/media/methods/Screen_Shot_2020-05-25_at_8.54.27_PM.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t0ibNdNq48J"
      },
      "source": [
        "# layer pertama dari model merupakan layer untuk melakukan proses embedding\n",
        "# dari token yang sudah dibuat. Angka 1000 di sini berarti jumlah token yang digunakan\n",
        "# dan 16 berarti dimensi vektor hasil embedding yang digunakan\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(1000, 16, input_length=50),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "hist = model.fit(pad_train, cls_train, epochs=5, validation_data=(pad_val, cls_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8lVTiK20i-z"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(pad_test, cls_test)\n",
        "print(\"=== Performance on Test Data: ===\")\n",
        "print(\"Loss:\", test_loss)\n",
        "print(\"Accuracy:\", test_acc, \"\\n\")\n",
        "\n",
        "plot_metrics(hist, ['accuracy'])\n",
        "\n",
        "print(\"\\n=== Some Test Samples: ===\")\n",
        "samples_idx = random.sample(range(len(pad_test)), 5)\n",
        "pad_samples = pad_test[samples_idx]\n",
        "preds = model.predict(pad_samples) >= 0.5\n",
        "for i, idx in enumerate(samples_idx):\n",
        "    pred_lab = \"Sarkas!\" if preds[i] else \"Netral\"\n",
        "    true_lab = \"Sarkas!\" if cls_test.iloc[idx] else \"Netral\"\n",
        "    print(f'[Pred: {pred_lab}; Truth: {true_lab}] \"{snt_test.iloc[idx]}\"')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6Ii8ah1wPwR"
      },
      "source": [
        "#### 1.2.2. Beberapa fitur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YflQfzyhmNzN"
      },
      "source": [
        "##### a. Summary dan Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0wAcKBuspRy"
      },
      "source": [
        "Untuk melihat secara ringkas data arsitektur model yang sudah dibangun, kita bisa gunakan metode `.summary`. Misalkan, untuk model RNN yang sudah dibangun sebelumnya kita punya summary seperti berikut."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7j-tJiJhgp2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4q0xE1Ahn3C"
      },
      "source": [
        "Terlihat ada 4 informasi untuk setiap layer, yakni nama layernya, tipe layer, bentuk output, dan parameter yang ada di layer tersebut. Hal ini akan memberikan gambaran pada kita bagaimana informasi terpropagasikan sepanjang model, dan juga memberi gambaran seberapa berat model yang kita miliki dari parameter yang dimilikinya. Semakin banyak parameter, semakin berat proses training. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wFRMhx9h-LW"
      },
      "source": [
        "Kita juga bisa melihat arsitektur model secara visual dengan fungsi `plot_model` dari module `tf.keras.utils`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jva574WSiD5m"
      },
      "source": [
        "tf.keras.utils.plot_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiAaccDTiM-q"
      },
      "source": [
        "Terlihat bagaimana bentuk model dari input sampai output. Terlihat juga bagaimana model sequential memang model yang \"lurus\". Di gambar di atas, hanya terlihat nama dan tipe layernya, jika ingin lebih lengkap, kita bsa tambahkan beberapa argumen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-A2LmPWiL6v"
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model, \n",
        "    to_file='model.png', # jika gambarnya mau disimapn \n",
        "    show_shapes=True,  #perlihatkan bentuk input dan outputnya\n",
        "    show_dtype=True, # perlihatkan tipe datanya \n",
        "    rankdir='LR' # mau horizontal/left-right (LR) atau vertikal/top-bottom (TB)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfAFoiGdmMLv"
      },
      "source": [
        "##### b. Save Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrEK6CGSmcZz"
      },
      "source": [
        "Model yang sudah didefinisikan, belum maupun sudah ditraining, dapat disimpan ke format default TF SavedModel (`.pb`) atau ke format yang lebih umum yakni HDF5 (`.h5`). Model ini kemudian bisa dimuat dan dilatih lagi di tempat lain ataupun di-deploy sesuai kebutuhan. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHJPfCBSjFLp"
      },
      "source": [
        "model.save('./sarcasm_detector.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS_S3bvejNNf"
      },
      "source": [
        "Untuk memuat kembali modelnya, cukup gunakan metode `load_model` seperti berikut"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XruMRb-LjhfF"
      },
      "source": [
        "loaded = tf.keras.models.load_model('./sarcasm_detector.h5')\n",
        "loaded.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfFMZSfijzc-"
      },
      "source": [
        "## 2. Middle Level API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tW3KB_ceBDx"
      },
      "source": [
        "Di level pertengahan, Tensorflow dapat digunakan dengan beberapa penyesuaian namun tetap terbungkus dengan baik dengan fitur-fitur lainnya. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t_TZiSBAdoE"
      },
      "source": [
        "### 2.3. Custom Components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gqjZFFzeQNM"
      },
      "source": [
        "Sudah terlihat sebelumnya bahwa ketika mendefinisikan dan mengimpilasi model *deep learning* di Tensorflow paling tidak terdapat 4 komponen yang bisa dipilih-pilih oleh user: *layer*, fungsi *loss*, *optimizer*, *metric*.\n",
        "\n",
        "Jika sebelumnya keempat komponen ini kita pakai langsung dari yang sudah disediakan oleh Tensorflow (dan Keras), dalam API yang lebih rendah, kita bisa membuat sendiri komponen yang kita inginkan menyesuaikan kebutuhan.\n",
        "\n",
        "![](https://raw.githubusercontent.com/phoenixfin/deeplearning-notebooks/main/model_components.png)\n",
        "\n",
        "Dari 4 komponen itu, akan dibahas 2 komponen yang paling sering diubah-ubah. Untuk optimizer dan metrik, biasanya user sudah merasa cukup dengan yang sudah ada.\n",
        "\n",
        "> NB: diasumsikan harus sudah paham konsep *Object-Oriented Programming*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o54e4-7CAggU"
      },
      "source": [
        "#### 2.3.1. Custom Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlYY_6DofRH6"
      },
      "source": [
        "Format dasar dari kelas Layer yang turun dari Tensorflow Keras adalah\n",
        "\n",
        "```\n",
        "class NamaLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        # di sini definisikan semua atribut yang akan digunakan\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # di sini inisialisasikan semua parameter yang terdapat\n",
        "        # di dalam layer dengan menyesuaikan bentuk input (input_shape)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        # di sini ditentukan apa yang dilakukan oleh layer ini jika\n",
        "        # dipanggil dengan suatu input\n",
        "```\n",
        "\n",
        "Pada kali ini, kita akan coba membangun ulang layer *Dense* yang  merupakan layer standar *Multi-Layer Perceptron*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnVrzRT6BPWl"
      },
      "source": [
        "class CustomDense(tf.keras.layers.Layer):\n",
        "    def __init__(self, units=32, activation=None):\n",
        "        super().__init__()\n",
        "        # units akan menentukan bentuk dari parameter W\n",
        "        self.units = units\n",
        "        \n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # setiap layer dense punya parameter W dan b\n",
        "        w_initializer = tf.random_normal_initializer()\n",
        "        w_init = w_initializer(shape = (input_shape[-1], self.units), \n",
        "                               dtype = 'float32')\n",
        "        b_initializer = tf.zeros_initializer()\n",
        "        b_init = b_initializer(shape=(self.units,), \n",
        "                               dtype='float32')\n",
        "        self.w = tf.Variable(w_init, name = \"kernel\", trainable=True)\n",
        "        self.b = tf.Variable(b_init, name = \"bias\", trainable=True)\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # ketika input masuk ke layer ini, maka dilakukan perhitungan linear\n",
        "        # dengan W dan b, serta diaktivasi dengan fungsi yang didefinisikan sebelumnya\n",
        "        return self.activation(tf.matmul(inputs, self.w) + self.b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEOL2A_8hX4J"
      },
      "source": [
        "Saatnya layer ini digunakan langsung di model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwTPJT4DkTyW"
      },
      "source": [
        "# bangun model persis seperti sebelumnya namun menggunakan layer Dense yang baru\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    CustomDense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(img_train, lab_train, epochs=5)\n",
        "\n",
        "print(\"\\nEvaluate...\")\n",
        "model.evaluate(img_val, lab_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7ANN4ptFUR8"
      },
      "source": [
        "#### 2.3.2. Custom Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT3rsXxTiY5I"
      },
      "source": [
        "Fungsi *loss* bisa didefinisikan dengan dua cara:\n",
        "- *Fungsi*. Dalam hal ini, fungsi yang didefinisikan harus hanya mendapat input *y_true* (output yang benar) dan *y_pred* (output prediksi). Jika ada parameter lain, maka fungsi yang didefinisikan cukup berperan sebagai *wrapper* untuk fungsi yang sesungguhnya.\n",
        "- *Kelas*. Minimal harus mengandung metode `call` yang mendapat input *y_true* dan *y_pred*. Jika ada parameter tambahan, bisa disesuaikan di konstruktor (`__init__`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvRZpxk2tGn6"
      },
      "source": [
        "# versi fungsi\n",
        "def huber_loss_function(threshold):\n",
        "    def huber_loss(y_true, y_pred):\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) <= threshold\n",
        "        small_error_loss = tf.square(error) / 2\n",
        "        big_error_loss = threshold * (tf.abs(error) - (0.5 * threshold))        \n",
        "        return tf.where(is_small_error, small_error_loss, big_error_loss) \n",
        "    # fungsi yang diluar mengembalikan fungsi yang sebenarnya, yang mengambil \n",
        "    # input y_true dan y_pred \n",
        "    return huber_loss\n",
        "\n",
        "# versi kelas\n",
        "class HuberLossClass(tf.keras.losses.Loss):\n",
        "    def __init__(self, threshold=1):\n",
        "        super().__init__()\n",
        "        self.threshold = threshold\n",
        "        \n",
        "    def call(self, y_true, y_pred):\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) <= self.threshold\n",
        "        small_error_loss = tf.square(error) / 2\n",
        "        big_error_loss = self.threshold * (tf.abs(error) - (0.5 * self.threshold))\n",
        "        return tf.where(is_small_error, small_error_loss, big_error_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7rgmb5qH5QX"
      },
      "source": [
        "model = tf.keras.Sequential([tf.keras.layers.Dense(units=1, input_shape=[1])])\n",
        "\n",
        "# silakan pilih akan gunakan versi fungsi / kelas\n",
        "model.compile(optimizer='sgd', loss = huber_loss_function(threshold=1.2))\n",
        "# model.compile(optimizer='sgd', loss = HuberLossClass(threshold=1.2))\n",
        "\n",
        "x = np.arange(10)\n",
        "y_true = 3.21*x + 1.4\n",
        "y_noise = y_true + tf.random.uniform((10,), minval=-10., maxval=10.)\n",
        "model.fit(x, y_noise, epochs=100)\n",
        "y_pred = model.predict(x)\n",
        "plt.plot(x, y_noise, 'o')\n",
        "plt.plot(x, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gu_W-6WGGSx"
      },
      "source": [
        "#### 2.3.3. Callback "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6Wi3wn8tzQG"
      },
      "source": [
        "*Callback* sederhananya merupakan aktivitas yang dilakukan di tengah-tengah proses training. *Callback* dimasukkan sebagai argumen ketika memanggil metode `fit` dari model. Ada beragam bentuk callback, dimana sebagian di antarnaya akan dibahas sebagian di sini.\n",
        "\n",
        "Sebelumnya, kita definisikan dulu pembangun model sederhana "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDBpWvHXCh2A"
      },
      "source": [
        "def build_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Reshape((28, 28, 1)),\n",
        "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# shortener\n",
        "cb = tf.keras.callbacks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zcOqFbKFsFp"
      },
      "source": [
        "##### a. Checkpoint Callback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT-tTK1iZmZz"
      },
      "source": [
        "Callback untuk menyimpan model dan parameternya setiap epoch. Hal ini bisa dimanfaatkan untuk banyak hal seperti keperluan untuk muat ulang kondisi model pada suatu epoch ketika ternyata performanya menurun di epoch selanjutnya. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYV4FJ8iMmDq"
      },
      "source": [
        "# kita bisa menyimpan berdasarkan epoch\n",
        "name_format = 'weights.{epoch:02d}-{val_loss:.2f}.h5'\n",
        "# atau satu file tunggal yang direplace setiap saat\n",
        "# name_format = 'saved_model.h5'\n",
        "\n",
        "cp_callback = cb.ModelCheckpoint(name_format, verbose=1)\n",
        "\n",
        "model = build_model()\n",
        "model.fit(img_train, lab_train, epochs=5, \n",
        "          validation_data=(img_val, lab_val), callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TeSgZA6OWKD"
      },
      "source": [
        "##### b. Early Stop Callback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK8XwKD-aWCI"
      },
      "source": [
        "Callback untuk menghentikan proses training bila ternyata performa modelnya tidak membaik dalam suatu rentang *patience* yang ditetapkan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJOJTJYdCkdY"
      },
      "source": [
        "model = build_model()\n",
        "stopper = cb.EarlyStopping(patience=3, min_delta=0.05, baseline=0.8,\n",
        "              mode='min', monitor='val_loss', restore_best_weights=True,\n",
        "              verbose=1)\n",
        "\n",
        "model.fit(img_train, lab_train, epochs=50, \n",
        "          validation_data=(img_val, lab_val), callbacks=[stopper])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvqcC4uwPA73"
      },
      "source": [
        "##### c. Logger Callback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TXOCvi2afGg"
      },
      "source": [
        "Logger Callback di TF sebenarnya selalu terpasang dalam kondisi *default*, yakni kemampuan untuk *logging* ketika training (terlihat bahwa setiap kita jalankan metode `fit`, kondisi setiap step/epoch akan tercetak dengan otomatis).\n",
        "\n",
        "Akan tetapi, ada logger lain yang diturunkan dari base logger tersebut, seperti csv logger bila kita ingin log tidak hanya dicetak di console, tapi juga disimpan dalam file csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cffnMpmGPtMh"
      },
      "source": [
        "model = build_model()\n",
        "csv_log = cb.CSVLogger('training.csv')\n",
        "prog_log = cb.ProgbarLogger('steps')\n",
        "\n",
        "model.fit(img_train, lab_train, epochs=5, \n",
        "          validation_data=(img_val, lab_val), callbacks=[csv_log, prog_log])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mpmRic5a74A"
      },
      "source": [
        "Kita lihat isi log yang sudah terbuat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9tkYi03QV7R"
      },
      "source": [
        "pd.read_csv('training.csv').head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQEakH1zPcvf"
      },
      "source": [
        "##### d. TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyoNJd2vbItw"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/site-assets/images/project-logos/tensorboard-logo-social.png\" alt=\"drawing\" height=\"200\"/>\n",
        "\n",
        "Tensorboard merupakan salah satu library khusus di TF yang menyediakan dashboard untuk analisis proses training. Ada banyak fitur yang disediakan. Berikut ini akan ditunjukkan fitur-fitur dasarnya. Mula-mula kita muat dulu ekstensi dari tensorboard. Jika ingin dibuka di lokal, Tensorboard bisa dipanggil langsung via terminal, asalkan package dari tensorflow sendiri sudah diinstall.\n",
        "\n",
        "Tensorboard sebenarnya membaca suatu log yang dituliskan khusus ketika process training. Untuk itu, kita perlu mendefinisikan callback agar log khusus tensorboard dapat dibuat selama training dilakukan.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeiD2WVEHbex"
      },
      "source": [
        "# muat ekstensi tensorboard\n",
        "%load_ext tensorboard\n",
        "\n",
        "# hapus dulu folder logs apabila sudah ada sebelumnya\n",
        "!rm -rf logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpLwPLnAEOzv"
      },
      "source": [
        "model = build_model()\n",
        "logdir = \"logs/\"+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard = cb.TensorBoard(logdir)\n",
        "\n",
        "model.fit(img_train, lab_train, epochs=5, \n",
        "          validation_data=(img_val, lab_val), callbacks=[tensorboard])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6yj2ANXj0q9"
      },
      "source": [
        "Setelah proses teraining selesai, kita bisa muat log yang sudah tercatat dengan tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z60F-1Ejxet"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYyDhAVUQzW6"
      },
      "source": [
        "##### e. Learning Rate Callback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UObeXSWmi3AN"
      },
      "source": [
        "*Learning Rate* (LR) merupakan salah satu hyperparameter yang cukup penting dalam proses training. Terkadang, LR yang terlalu besar bisa membuat model gagal mendekati titik optimum, sedangkan LR yang terlalu kecil akan membuat proses training jadi sangat lambat. Untuk itu, LR perlu dibuat dinamis, bukannya konstan sepanjang training.\n",
        "\n",
        "Dalam konteks itu, kita bisa memanfaatkan callback untuk mengatur sehingga LR akan berkurang seiring epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4naxZ-eCFB27"
      },
      "source": [
        "!rm -rf logs\n",
        "\n",
        "# menetapkan metrik tambahan untuk dibuka di tensorboard\n",
        "writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
        "writer.set_as_default()\n",
        "initial_lr = 0.2\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    # membuat LR decay secara eksponensial\n",
        "    decay_rate = 1e-1\n",
        "    lr = initial_lr * np.exp(-decay_rate * epoch)\n",
        "    # menuliskan LR di log\n",
        "    tf.summary.scalar('learning rate', data=lr, step=epoch)\n",
        "    return lr\n",
        "\n",
        "lr_callback = cb.LearningRateScheduler(lr_schedule)\n",
        "tensorboard = cb.TensorBoard(log_dir=logdir)\n",
        "\n",
        "model = build_model()\n",
        "model.fit(img_train, lab_train, epochs=5, \n",
        "          validation_data=(img_val, lab_val), \n",
        "          callbacks=[tensorboard, lr_callback])\n",
        "\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcrRB6lnG7Aq"
      },
      "source": [
        "##### f. Custom Callback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s9GXp3ykekq"
      },
      "source": [
        "Custom callback berisi metode yang dilakukan pada setiap awal dan akhir epoch ataupun batch. Formatnya kurang lebih seperti berikut\n",
        "```\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        # inisiasi atribut\n",
        "        \n",
        "    def on_epoch_begin(self, epoch, logs):\n",
        "        # callback ketika epoch dimulai\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        # callback ketika epoch berakhir\n",
        "\n",
        "    def on_batch_begin(self, batch, logs):\n",
        "        # callback ketika batch dimulai\n",
        "\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        # callback ketika batch berakhir     \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BIh7Za8GJCa"
      },
      "source": [
        "class CustomCallback(cb.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        print('Proses training untuk epoch {} mulai pada {}'.format(epoch, datetime.datetime.now().time()))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print('Proses training untuk epoch {} bearkhir pada {}'.format(epoch, datetime.datetime.now().time()))\n",
        "\n",
        "model = build_model()\n",
        "model.fit(img_train, lab_train, epochs=1, validation_data=(img_val, lab_val), \n",
        "          callbacks=[CustomCallback()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXgirhnvj28S"
      },
      "source": [
        "### 2.2. Functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMghHDhkwdFD"
      },
      "source": [
        "Model NN terkadang seperti hidup, tidak selalu lurus terus, terkadang harus bercabang dan berkelok-kelok, maka model Sequential tidak akan bisa berbuat banyak. \n",
        "\n",
        "Functional API memosisikan layer dari NN seperti fungsi, yang dipanggil dengan suatu input dan menghasilkan output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e_Y5S1cIdr4"
      },
      "source": [
        "#### 2.2.1. Branching Model\n",
        "\n",
        "Kasus yang akan  kita buat kali ini adalah model jaringan Siamese. Model ini biasanya digunakan untuk proses identifikasi gambar, terutama ketika dataset terkait gambar tersebut tidak banyak. Contohnya adalah identifikasi wajah, dimana kita tidak mungkin melatih suatu model ML karena data wajah spesifik setiap individu tidaklah banyak. Jadi, kita cukup melatih model agar bisa mengatakan apakah dua gambar itu mirip atau tidak. Kurang lebih bentuknya seperti ini \n",
        "\n",
        "![](https://people.kth.se/~rosun/deep-learning/figures/siamese-arch.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xPpmYiwxoju"
      },
      "source": [
        "Kita definisikan dulu fungsi untuk membuat pasangannya. Data yang dimasukkan harus berisi dua macam pasang, yakni pasangan yang mirip dan pasangan yang tidak mirip, sehingga model akan berusaha membedakan mana pasangan yang mirip mana yang tidak"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSQMl9cZkgDx"
      },
      "source": [
        "def create_pairs(images, digits):\n",
        "    pairs = []\n",
        "    labels = []\n",
        "\n",
        "    digit_indices = [np.where(digits == i)[0] for i in range(10)]\n",
        "    n = min([len(digit_indices[d]) for d in range(10)]) - 1\n",
        "    for digit in range(10):\n",
        "        for i in range(n):\n",
        "            idx1 = digit_indices[digit][i]\n",
        "            idx2 = digit_indices[digit][i + 1]\n",
        "            pairs += [[images[idx1], images[idx2]]]\n",
        "\n",
        "            other_digit = (digit + random.randrange(1, 10)) % 10            \n",
        "            idx1 = digit_indices[digit][i]\n",
        "            idx2 = digit_indices[other_digit][i]\n",
        "            pairs += [[images[idx1], images[idx2]]]\n",
        "\n",
        "            labels += [1, 0]\n",
        "\n",
        "    return np.array(pairs), np.array(labels).astype('float')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlvAwipLxpGK"
      },
      "source": [
        "Selanjutnya kita siapkan semua datanya menjadi pasangan-pasangan gambar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ook7lKQakomz"
      },
      "source": [
        "train_pairs, train_y = create_pairs(img_train, lab_train)\n",
        "val_pairs, val_y = create_pairs(img_val, lab_val)\n",
        "test_pairs, test_y = create_pairs(img_test, lab_test)\n",
        "\n",
        "sample = random.randint(0,10)\n",
        "\n",
        "fig, axs = plt.subplots(1,2)\n",
        "axs[0].imshow(val_pairs[sample][0])\n",
        "axs[1].imshow(val_pairs[sample][1])\n",
        "\n",
        "status = \"MIRIP!\" if train_y[sample] else \"INI BEDA\"\n",
        "print(status)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMo2HbKLkuAa"
      },
      "source": [
        "input = tf.keras.Input(shape=(28,28,))\n",
        "x = tf.keras.layers.Flatten()(input)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "base_network = tf.keras.Model(inputs=input, outputs=x)\n",
        "\n",
        "# metode plot_model dapat digunakan untuk menggambar model yang dibangun\n",
        "tf.keras.utils.plot_model(base_network, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC30AatGx3PR"
      },
      "source": [
        "Hasil olahan dari jaringan ini adalah berupa vektor yang merepresentasikan fitur dari gambar input. Kita kemudian mendefinisikan fungsi jarak euklid sebagai ukuran pembeda dari 2 fitur gambar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W8vL_pDVoo1"
      },
      "source": [
        "def euclidean_distance(xy_pair):\n",
        "    x, y = xy_pair\n",
        "    sum_square = tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True)\n",
        "    return tf.sqrt(tf.maximum(sum_square, tf.keras.backend.epsilon()))\n",
        "\n",
        "def split_output(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQVJmeUtyVJ7"
      },
      "source": [
        "Selanjutnya kita gabungkan dua jaringan menjadi satu jaringan dengan memasukkannya secara fungsional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe4YNz0kkwq5"
      },
      "source": [
        "input_a = tf.keras.Input(shape=(28,28,))\n",
        "input_b = tf.keras.Input(shape=(28,28,))\n",
        "distance_check = tf.keras.layers.Lambda(euclidean_distance, output_shape = split_output)\n",
        "\n",
        "output_a = base_network(input_a)\n",
        "output_b = base_network(input_b)\n",
        "output = distance_check([output_a, output_b])\n",
        "\n",
        "model = tf.keras.Model([input_a, input_b], output)\n",
        "\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKM5b6GGy9oN"
      },
      "source": [
        "Kita bisa gambarkan juga diagram modelnya secara lengkap dengan menambahkan argumen `expand_nested`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TogloHKZySCG"
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HswzRyDAk-V7"
      },
      "source": [
        "def contrastive_loss_func(margin):\n",
        "    def contrastive_loss(y_true, y_pred):\n",
        "        '''\n",
        "        Hadsell-et-al. 2006 \n",
        "        (http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf)\n",
        "        '''\n",
        "        square_pred = tf.square(y_pred)\n",
        "        margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
        "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
        "    return contrastive_loss\n",
        "\n",
        "train_x = [train_pairs[:,0], train_pairs[:,1]]\n",
        "val_x = [val_pairs[:,0], val_pairs[:,1]]\n",
        "test_x = [test_pairs[:, 0], test_pairs[:, 1]]\n",
        "\n",
        "model.compile(loss = contrastive_loss_func(margin=1), optimizer='RMSprop')\n",
        "history = model.fit(train_x, train_y, epochs=5, batch_size=128, validation_data=(val_x, val_y))    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyfJWzjYlKMg"
      },
      "source": [
        "def compute_accuracy(y_true, y_pred):\n",
        "    pred = y_pred.ravel() < 0.5\n",
        "    return np.mean(pred == y_true)\n",
        "    \n",
        "loss = model.evaluate(x= test_x, y=test_y)\n",
        "y_pred_test = model.predict(test_x)\n",
        "test_accuracy = compute_accuracy(test_y, y_pred_test)\n",
        "print(\"Loss = {},\\nTest Accuracy = {}\".format(loss, test_accuracy))\n",
        "\n",
        "idxs = [random.randint(0, len(test_pairs)) for _ in range(5)]\n",
        "samples = [test_pairs[idxs, 0], test_pairs[idxs, 1]]\n",
        "preds = model.predict(samples).ravel() < 0.5\n",
        "preds = [\"Mirip\" if pred else \"Beda\" for pred in preds]\n",
        "show_figures(samples, preds, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pQ9-TPpKN6c"
      },
      "source": [
        "#### 2.2.2. Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xgb0r_H8B5E"
      },
      "source": [
        "Ketika orang lain sudah membangun suatu model NN yang baik, kenapa kita tidak memanfaatkannya? Dari sini muncul teknik yang disebut *Transfer Learning*, yakni penggunaan kembali hasil *learning* model lain, untuk disesuaikan dengan kasus milik kita. Tensorflow menyediakan 2 sumber untuk ini, yakni Keras Application dan TFHub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp2CLyHNSITr"
      },
      "source": [
        "###### a. Keras Application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmTkILay8cxb"
      },
      "source": [
        "Keras Application berisi model-model (CNN) terkenal yang siap pakai, seperti Inception, ResNet, DenseNet, dll. Kita coba langsung pakai untuk prediksi suatu gambar. Kali ini kita akan gunakan model Inception V3 [(Szegedy, et al, 2016)](https://arxiv.org/abs/1512.00567), yang merupakan pengembangan dari model Inception [(Szegedy, et al, 2014)](https://arxiv.org/abs/1409.4842). Kurang lebih modelnya seperti berikut\n",
        "\n",
        "![](https://www.researchgate.net/profile/Masoud-Mahdianpari/publication/326421398/figure/fig6/AS:649353890889730@1531829440919/Schematic-diagram-of-InceptionV3-model-compressed-view.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoBCnh3GUiwX"
      },
      "source": [
        "im_file = tf.keras.utils.get_file('image.jpg','https://cinemags.co.id/wp-content/uploads/2021/03/godzilla-vs-kong-cast-characters-slideshow-1612488494005.jpg')\n",
        "gorilakong = PIL.Image.open(im_file)\n",
        "im = gorilakong.resize((299,299))\n",
        "im = np.array(im)/255.0\n",
        "plt.imshow(im)\n",
        "\n",
        "base_model = tf.keras.applications.InceptionV3(weights=\"imagenet\", \n",
        "                                               input_shape=(299, 299, 3), \n",
        "                                               include_top=True)\n",
        "pred = base_model.predict(tf.expand_dims(im, 0))\n",
        "tf.keras.applications.inception_v3.decode_predictions(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofe-WZxD8vMq"
      },
      "source": [
        "Selanjutnya, kita coba pergunakan modelnya, atau dilatih ulang, untuk kita sesuaikan outputnya dengan label yang ada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMUSRg9yKTBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4236e8cb-6572-4d43-867c-cfd90d396439"
      },
      "source": [
        "img_tr = np.array([prepare_image(img, (150, 150), tf.keras.applications.inception_v3) for img in img_train[:2000]])\n",
        "base_model = tf.keras.applications.InceptionV3(weights=\"imagenet\", \n",
        "                                               input_shape=(150, 150, 3), \n",
        "                                               include_top=False)\n",
        "base_model.trainable = False\n",
        "\n",
        "input = tf.keras.Input(shape=(150,150,3))\n",
        "x = base_model(input)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)  \n",
        "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "model = tf.keras.Model(input, outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(img_tr, lab_train[:2000], epochs = 2)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "63/63 [==============================] - 81s 1s/step - loss: 2.2020 - accuracy: 0.3226\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 77s 1s/step - loss: 1.8735 - accuracy: 0.7267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f67bd897610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlMFmObXF1Rr"
      },
      "source": [
        "img_ts = np.array([prepare_image(img, (150, 150), tf.keras.applications.inception_v3) for img in img_test[:5]])\n",
        "\n",
        "predicted = model.predict(img_ts)\n",
        "pred_label = np.argmax(predicted, axis=-1)\n",
        "\n",
        "show_figures(img_ts, pred_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOY0WXDOSL9J"
      },
      "source": [
        "###### b. TF Hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deTuZv6C9HX7"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/site-assets/images/project-logos/tensorflow-hub-logo-social.png\" alt=\"drawing\" height=\"200\"/>\n",
        "\n",
        "TFHub atau Tensorflow Hub berisi model-model dengan berbagai keperluan dan studi kasus dari peneliti/pengembang lain yang siap dimanfaatkan. Model dari TFHhub memiliki beragam fungsi, baik yang berupa classifier langsung atau yang hanya feature extractor.\n",
        "\n",
        "Mula-mula kita coba dulu pakai model yang sudah jadi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "4kn4FtyVSQlq"
      },
      "source": [
        "classifier_model =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxG_wJ1dSuzU"
      },
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "\n",
        "classifier = tf.keras.Sequential([\n",
        "    hub.KerasLayer(classifier_model, input_shape=IMAGE_SHAPE+(3,))\n",
        "])"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5wDjXNjuXGD"
      },
      "source": [
        "im = gorilakong.resize(IMAGE_SHAPE)\n",
        "im = np.array(im)/255.0\n",
        "\n",
        "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
        "imagenet_labels = np.array(open(labels_path).read().splitlines())\n",
        "\n",
        "result = classifier.predict(im[np.newaxis, ...])\n",
        "predicted_class = np.argmax(result[0], axis=-1)\n",
        "imagenet_labels[predicted_class]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B99OEEhxmpTN"
      },
      "source": [
        "Sekarang, kita coba pakai model feature extractor untuk dilatih kembali dengan dataset lain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bw8Jf94DSnP",
        "cellView": "form"
      },
      "source": [
        "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wB030nezBwI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b690f818-9953-4302-85bd-56de8a41925c"
      },
      "source": [
        "img_tr = np.array([prepare_image(img, IMAGE_SHAPE) for img in img_train[:2000]])\n",
        "feature_extractor_layer = hub.KerasLayer(feature_extractor_model, input_shape=(224, 224, 3), trainable=False)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    feature_extractor_layer,\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(img_tr, lab_train[:2000], epochs=2)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_3 (KerasLayer)   (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 10)                12810     \n",
            "=================================================================\n",
            "Total params: 2,270,794\n",
            "Trainable params: 12,810\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "63/63 [==============================] - 78s 1s/step - loss: 1.7814 - accuracy: 0.4158\n",
            "Epoch 2/2\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.5826 - accuracy: 0.8757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGbEf5l1I4jz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "4bf2ef3d-00b7-4bbd-f640-207b1678cdae"
      },
      "source": [
        "img_ts = np.array([prepare_image(img, IMAGE_SHAPE) for img in img_test[:5]])\n",
        "\n",
        "predicted = model.predict(img_ts)\n",
        "pred_label = np.argmax(predicted, axis=-1)\n",
        "show_figures(img_ts, pred_label)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "locobZSz_wU9"
      },
      "source": [
        "### 2.2. Model Subclassing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ynlk5kGxIrK"
      },
      "source": [
        "Selain dengan sequential atau functional, membuat model bisa lebih leluasa dengan membuat subclass langsung dari Model Keras.\n",
        "\n",
        "Membuat struktur dari sebuah subclass dari model mirip dengan bagaimana membangun subclass dari layer, yakni sebagai berikut\n",
        "```\n",
        "class NamaModel(tf.keras.Model):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        # inisiasi atribut\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # aktivitas yang dilakukan pada input di dalam model\n",
        "        return output\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKnGtNeQxuuW"
      },
      "source": [
        "Kali ini kita akan mencoba membangun sebuah miniatur dari model Residual Network (ResNet). Miniatur ini kurang lebih akan berbentuk seperti ini\n",
        "\n",
        "![](https://github.com/phoenixfin/deeplearning-notebooks/blob/main/dummy_resnet.png?raw=true)\n",
        "\n",
        "Dalam Identity Block, terdapat *skip connection* (disebut juga residual) yang menghubungkan ujung ke ujung untuk mempertahankan keutuhan informasi yang dipropagasikan. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FIkYUttchv5"
      },
      "source": [
        "class IdentityBlock(tf.keras.Model):\n",
        "    def __init__(self, filters, kernel_size):\n",
        "        super(IdentityBlock, self).__init__(name='')\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.act = tf.keras.layers.Activation('relu')\n",
        "        self.add = tf.keras.layers.Add()\n",
        "    \n",
        "    def call(self, input_tensor):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.bn1(x)\n",
        "        x = self.act(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        x = self.add([x, input_tensor])\n",
        "        x = self.act(x)\n",
        "        return x"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH4hurTSCgKL"
      },
      "source": [
        "Kita definiskan sekarang model ResNet yang lengkapnya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnMkmeecxw28"
      },
      "source": [
        "class ResNet(tf.keras.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.reshaper = tf.keras.layers.Reshape((28,28,1))\n",
        "        self.conv = tf.keras.layers.Conv2D(64, 7, padding='same')\n",
        "        self.bn = tf.keras.layers.BatchNormalization()\n",
        "        self.act = tf.keras.layers.Activation('relu')\n",
        "        self.max_pool = tf.keras.layers.MaxPool2D((3, 3))\n",
        "\n",
        "        self.id1a = IdentityBlock(64, 3)\n",
        "        self.id1b = IdentityBlock(64, 3)\n",
        "\n",
        "        self.global_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.reshaper(inputs)\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.act(x)\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = self.id1a(x)\n",
        "        x = self.id1b(x)\n",
        "\n",
        "        x = self.global_pool(x)\n",
        "        return self.classifier(x)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dMHKPz_dIc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "256e654c-a01b-4c8d-b025-22f1744f8396"
      },
      "source": [
        "resnet = ResNet(10)\n",
        "resnet.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "resnet.fit(img_train, lab_train, epochs=1)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1500/1500 [==============================] - 188s 125ms/step - loss: 0.3203 - accuracy: 0.9166\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f67ba754ad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlLF59mKm-UD"
      },
      "source": [
        "Cara membuat model bisa campuran sequential, functional, maupun subclassing. Sebagai contoh, membangun ResNet di atas bisa juga dituliskan seperti ini"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBuDf4LEnFpK"
      },
      "source": [
        "class IdentityBlock(tf.keras.Model):\n",
        "    def __init__(self, filters, kernel_size):\n",
        "        super(IdentityBlock, self).__init__(name='')\n",
        "        self.seq = tf.keras.Sequential([\n",
        "            tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
        "            tf.keras.layers.BatchNormalization()\n",
        "            tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
        "            tf.keras.layers.BatchNormalization()\n",
        "            tf.keras.layers.Activation('relu')                            \n",
        "        ])\n",
        "        self.add = tf.keras.layers.Add()\n",
        "    \n",
        "    def call(self, input_tensor):\n",
        "        x = self.seq(input_tensor)\n",
        "        x = self.add([x, input_tensor])\n",
        "        x = self.act(x)\n",
        "        return x\n",
        "\n",
        "resnet = tf.keras.Sequential([\n",
        "    tf.keras.layers.Reshape((28,28,1))\n",
        "    tf.keras.layers.Conv2D(64, 7, padding='same')\n",
        "    tf.keras.layers.BatchNormalization()\n",
        "    tf.keras.layers.Activation('relu')\n",
        "    tf.keras.layers.MaxPool2D((3, 3))\n",
        "    IdentityBlock(64, 3)\n",
        "    IdentityBlock(64, 3)\n",
        "    tf.keras.layers.GlobalAveragePooling2D()\n",
        "    tf.keras.layers.Dense(10, activation='softmax')                                        \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y9rJ8A8GcM2"
      },
      "source": [
        "## 3. Low Level API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAiivpyXONy2"
      },
      "source": [
        "### 3.1. Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBy3Kz8wOQo9"
      },
      "source": [
        "#### 3.1.1. Tensor Konstan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6i3_eOiNDjm"
      },
      "source": [
        "Tensor konstan merupakan tensor biasa seperti halnya array yang nilainya bisa dimanipulasi. Berikut beberapa terminologi yang dipakai (agak berbeda dari terminologi matematis):\n",
        "- *Axis* / *Dimension*: Suatu \"basis\" dari tensor tersebut \n",
        "- *Shape*: Tuple yang berisi banyaknya elemen dari setiap basis\n",
        "- *Rank*: Panjang dari *shape*, atau banyaknya basis\n",
        "- *Size*: Total banyaknya elemen di tensor\n",
        "\n",
        "Contoh, misal kita miliki tensor $x$ berbentuk matriks $2\\times 2$. Maka, $x$ memiliki rank-2 dengan bentuk atau *shape* (2, 2), dengan *axis* pertama sebagai baris dan *axis* kedua sebagai kolom, serta secara total berukuran 4.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5JcgLFR6gHv"
      },
      "source": [
        "rank_0_tensor = tf.constant(4)\n",
        "rank_1_tensor = tf.constant([2.0, 3.0, 4.0])\n",
        "rank_2_tensor = tf.constant([[1, 2],\n",
        "                             [3, 4],\n",
        "                             [5, 6]], dtype=tf.float16)\n",
        "rank_3_tensor = tf.constant([[[ 0,  1,  2,  3,  4],\n",
        "                              [ 5,  6,  7,  8,  9]],\n",
        "                             [[10, 11, 12, 13, 14],\n",
        "                              [15, 16, 17, 18, 19]],\n",
        "                             [[20, 21, 22, 23, 24],\n",
        "                              [25, 26, 27, 28, 29]],])\n",
        "\n",
        "print(\"Rank 0:\", rank_0_tensor)\n",
        "print(\"\\nRank 1:\", rank_1_tensor)\n",
        "print(\"\\nRank 2:\", rank_2_tensor)\n",
        "print(\"\\nRank 3:\", rank_3_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVTSYrNPP873"
      },
      "source": [
        "Mengubah tensor menjadi array bisa dilakukan 2 cara:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5u6_6ZYaS7B"
      },
      "source": [
        "np.array(rank_2_tensor)\n",
        "rank_2_tensor.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2lDUghlP_7L"
      },
      "source": [
        "Kita juga bisa membangun otomatis suatu tensor bentuk umum atau secara acak"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8ENkZBnP_jQ"
      },
      "source": [
        "random_ts1 = tf.random.normal((2,2), mean=0, stddev=1)\n",
        "random_ts2 = tf.random.uniform((2,2), minval=0, maxval=2)\n",
        "\n",
        "ones = tf.ones((2,2))\n",
        "zeros = tf.zeros((2,2))\n",
        "id = tf.eye(2)\n",
        "\n",
        "print(\"Tensor of Ones:\", ones,\"\\n\")\n",
        "print(\"Tensor of Zeros:\", zeros,\"\\n\")\n",
        "print(\"Identity Tensor:\", id,\"\\n\")\n",
        "print(\"Normal random tensor:\", random_ts1,\"\\n\")\n",
        "print(\"Uniform random tensor:\", random_ts2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi-JmwYeQNJQ"
      },
      "source": [
        "Kita juga bisa memanipulasi bentuk dari tensor yang sudah ada dengan beragam operasi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJfm_34vSoHE"
      },
      "source": [
        "t = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"=== Kita bisa terapkan padding:\\n\")\n",
        "paddings = tf.constant([[1, 1,], [2, 2]])\n",
        "print(\"Padding constant:\", tf.pad(t, paddings, \"CONSTANT\"),\"\\n\")\n",
        "print(\"Padding reflect:\", tf.pad(t, paddings, \"REFLECT\"),\"\\n\")\n",
        "print(\"Padding symmetric:\", tf.pad(t, paddings, \"SYMMETRIC\"),\"\\n\")\n",
        "\n",
        "print(\"=== Dimensinya bisa ditambah:\\n\")\n",
        "print(\"Tambah dimensi di axis pertama:\", tf.expand_dims(t, 0),\"\\n\")\n",
        "print(\"Tambah dimensi di axis kedua:\",tf.expand_dims(t, 1),\"\\n\")\n",
        "print(\"Tambah dimensi di axis ketiga:\",tf.expand_dims(t, 2),\"\\n\")\n",
        "\n",
        "print(\"=== Bisa di-reshape juga:\",\"\\n\")\n",
        "print(tf.reshape(t, (6,)),\"\\n\")\n",
        "print(tf.reshape(t, (3,2)),\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8LNRmXfQ7Sw"
      },
      "source": [
        "Kita bisa bikin tensor dari beragam tipe data yang lain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRmYRuQJXYfZ"
      },
      "source": [
        "lst = [1,2,3,4]\n",
        "tupl = (1,2,3,4)\n",
        "arr = np.array([1,2,3,4])\n",
        "srs = pd.Series([1,2,3,4])\n",
        "df = pd.DataFrame({'a':[1,2,3,4],'b':[5,6,7,8]})\n",
        "\n",
        "lst_ts = tf.convert_to_tensor(lst)\n",
        "tupl_ts = tf.convert_to_tensor(tupl)\n",
        "arr_ts = tf.convert_to_tensor(arr)\n",
        "srs_ts = tf.convert_to_tensor(srs)\n",
        "df_ts = tf.convert_to_tensor(df)\n",
        "\n",
        "print(\"Dari List:\", lst_ts)\n",
        "print(\"Dari Tuple:\", tupl_ts)\n",
        "print(\"Dari Array:\", arr_ts)\n",
        "print(\"Dari Series:\", srs_ts)\n",
        "print(\"Dari DataFrame:\", df_ts)\n",
        "print(\"Dari List:\", lst_ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R55aIQ7YoTRC"
      },
      "source": [
        "#### 3.1.2. Operasi Matematika"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNef96CYRbBb"
      },
      "source": [
        "Kita bisa jalankan operasi aritmatika dasar dengan 2 cara:\n",
        "- Dengan metode dari TF, seperti `tf.add` atau `tf.multiply`, atau\n",
        "- Dengan *operator overloading*, seperti `+`, `*`, atau `@`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DTkjwDOIIDa"
      },
      "source": [
        "a = tf.constant([[1, 2],\n",
        "                 [3, 4]])\n",
        "b = tf.constant([[1, 1],\n",
        "                 [1, 1]]) \n",
        "\n",
        "print(\"--- Penjumlahan ---\")\n",
        "print(tf.add(a, b), \"\\n\")\n",
        "print(a + b, \"\\n\") \n",
        "\n",
        "print(\"--- Perkalian per elemen ---\")\n",
        "print(tf.multiply(a, b), \"\\n\")\n",
        "print(a * b, \"\\n\") \n",
        "\n",
        "print(\"--- Perkalian matriks ---\")\n",
        "print(tf.matmul(a, b), \"\\n\")\n",
        "print(a @ b, \"\\n\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3_vIAl2JPVc"
      },
      "source": [
        "Berbagai fungsi matematis juga tersedia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp4WUYzGIbnv"
      },
      "source": [
        "c = tf.constant([[4.5, 5.3], [10.1, -1.0]])\n",
        "\n",
        "print(\"Original: \", c)\n",
        "print(\"\\nRound:\", tf.round(c))\n",
        "print(\"\\nAbsolute:\", tf.abs(c))\n",
        "print(\"\\nMaximum:\", tf.reduce_max(c))\n",
        "print(\"\\nMaximum Index:\", tf.argmax(c))\n",
        "\n",
        "print(\"\\nExponent:\", tf.exp(c))\n",
        "print(\"\\nPower of 2:\", tf.pow(c,2))\n",
        "print(\"\\nSquare Root:\", tf.sqrt(c))\n",
        "print(\"\\nSine:\", tf.sin(c))\n",
        "\n",
        "print(\"\\nCumulative Sum:\", tf.cumsum(c))\n",
        "print(\"\\nReduced Sum:\", tf.reduce_sum(c))\n",
        "print(\"\\nMean:\", tf.reduce_mean(c))\n",
        "print(\"\\nStandard Deviation:\", tf.math.reduce_std(c))\n",
        "\n",
        "print(\"\\nSigmoid:\", tf.nn.sigmoid(c))\n",
        "print(\"\\nSoftmax:\", tf.nn.softmax(c))\n",
        "print(\"\\nRelu:\", tf.nn.relu(c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABtJQmvTYh-B"
      },
      "source": [
        "Bisa juga bermain bilangan kompleks dengant tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX-7_RK0UFx1"
      },
      "source": [
        "d = tf.complex(1., 2.)\n",
        "\n",
        "print(d)\n",
        "print(\"Real part:\",tf.math.real(d))\n",
        "print(\"Imagninary part:\",tf.math.imag(d))\n",
        "print(\"Args:\",tf.math.angle(d))\n",
        "print(\"Absolute:\", tf.math.abs(d))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TVhQhbWYxuz"
      },
      "source": [
        "Library khusus aljabar linier juga ada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWFnTciwY-m2"
      },
      "source": [
        "e = tf.constant([[1.,2.], [3.,4.]])\n",
        "print(e)\n",
        "\n",
        "eigval, eigvec = tf.linalg.eig(e)\n",
        "inverse = tf.linalg.inv(e)\n",
        "Sig, U, V = tf.linalg.svd(e)\n",
        "adj = tf.linalg.adjoint(e)\n",
        "det = tf.linalg.det(e)\n",
        "diag = tf.linalg.diag_part(e)\n",
        "\n",
        "print(\"\\nNilai Eigen:\", eigval)\n",
        "print(\"\\nVector Eigen:\", eigvec)\n",
        "print(\"\\nNilai Singular:\", Sig)\n",
        "print(\"\\nAdjoint:\", adj)\n",
        "print(\"\\nDeterminan:\", det)\n",
        "print(\"\\nKomponen Diagonal:\", diag)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnmv_jGuYLOz"
      },
      "source": [
        "#### 3.1.3. Bentuk Lain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmaEdPD-Y8W9"
      },
      "source": [
        "Tensor di TF juga punya tensor bentuk lain seperti:\n",
        "- Ragged Tensor, tensor yang jumlah elemen di salah satu dimensinya tidak menentu atau berbeda-beda.\n",
        "- Sparse Tensor, tensor yang isinya sebagian besar 0 kecuali di beberapa posisi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4xKTo57tutG"
      },
      "source": [
        "ragged_list = [\n",
        "    [0, 1, 2, 3],\n",
        "    [4, 5],\n",
        "    [6, 7, 8],\n",
        "    [9]]\n",
        "    \n",
        "tensor = tf.constant(ragged_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhF3QV3jiqTj"
      },
      "source": [
        "ragged_tensor = tf.ragged.constant(ragged_list)\n",
        "print(ragged_tensor)\n",
        "print(ragged_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9nbO1E2kSUN"
      },
      "source": [
        "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
        "                                       values=[1, 2],\n",
        "                                       dense_shape=[3, 4])\n",
        "print(sparse_tensor, \"\\n\")\n",
        "print(tf.sparse.to_dense(sparse_tensor))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEuZONq6LDGR"
      },
      "source": [
        "### 3.2. Dataset API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsdQgdQj8ahu"
      },
      "source": [
        "Dataset API merupakan framework pengelolaan dataset yang dibuat oleh tensorflow di bawah modul `tf.data`. Berikut akan diperlihatkan bagaimana API ini bekerja."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdKa97WlbxCO"
      },
      "source": [
        "#### 3.2.1. Data Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm6tO_RT8od4"
      },
      "source": [
        "Salah satu fungsi dari API ini adalah kemudahan dalam pembuatan data pipeline, sehingga dari data mentah sampai masuk ke model, itu semua bisa di-handle dengan lebih kompak. Kasus penggunaannya cukup banyak, untuk kali ini akan didemonstrasikan penggunaannya pada pembuatan data *time series*.\n",
        "\n",
        "Mula-mula, misalkan kita punya data *time series* yang digenerate dari 1 sampai 100. Membuat Dataset-nya cukup dengan metode `from_tensor_slices` dari modul `tf.data.Dataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpEcisr-Z89i"
      },
      "source": [
        "series = np.arange(100)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvBHQ8C79NK3"
      },
      "source": [
        "Perhatikan bahwa hasil dataset yang dibuat sudah berupa bundel objek dari kelas `TensorSliceDataset`. Untuk melihat isinya, gunakan metode `take`, dengan argumen banyaknya data yang mau diambil."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0PZAFx6aM3J"
      },
      "source": [
        "for data in dataset.take(10):\n",
        "    print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K_-AlOo9Z_g"
      },
      "source": [
        "Dapat kita lihat bahwa setiap komponen data-nya sekarang sudah otomatis menjadi Tensor. Selanjutnya, kita akan membuat *window*, yakni suatu rentang data yang akan dianggap sebagai satu set input. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5Nksuj0aJ7c"
      },
      "source": [
        "dataset = dataset.window(4, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(4))\n",
        "\n",
        "for data in dataset.take(10):\n",
        "    print(data.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xivTn7i29oiq"
      },
      "source": [
        "Sekarang, kita sudah miliki data yang berisi kumpulan *window* berisi 4 nilai. Data ini kemudian kita acak untuk menghilangkan bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0PkJQUzagEk"
      },
      "source": [
        "dataset = dataset.shuffle(1000)\n",
        "for data in dataset.take(10):\n",
        "    print(data.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGpEaRZv90uw"
      },
      "source": [
        "Kita kemudian akan membuat label (target) dari setiap data ini. Dalam suatu model *time series*, bila diberi input suatu rentang data berurutan, maka kita ingin modelnya bisa memprediksi nilai di waktu berikutnya. Maka dari itu, kita ambil nilai terakhir dari setiap *window* sebagai labelnya. Kita gunakan metode `map` yang akan memroses setiap data satu per satu melalui fungsi yang dimasukkan sebagai argumen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5YP3UlrcGCN"
      },
      "source": [
        "dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "for data, label in dataset.take(10):\n",
        "    print(data.numpy(),'->', label.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa-NmrIJ-Xac"
      },
      "source": [
        "Kita kemudian kelompokkan lagi data-data ini menjadi batch berisi 10 window."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SVcj-ZUcUzI"
      },
      "source": [
        "dataset = dataset.batch(10)\n",
        "for data, label in dataset.take(2):\n",
        "    print(data.numpy(),'->', label.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAfzxJod-hId"
      },
      "source": [
        "Secara keseluruhan, pipeline yang kita buat akan seperti ini"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pegrBEzQV0O-"
      },
      "source": [
        "# Secara keseluruhan  jadi seperti ini\n",
        "ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "ds = ds.window(4, shift=1, drop_remainder=True)\n",
        "ds = ds.flat_map(lambda window: window.batch(4))\n",
        "ds = ds.shuffle(1000)\n",
        "ds = ds.map(lambda window: (window[:-1], window[-1]))\n",
        "ds = ds.batch(10)\n",
        "ds = ds.prefetech(1) # ini tambahan untuk meningkatkan performa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqEymB4R-t_V"
      },
      "source": [
        "Variabel `ds` ini dapat langsung dimasukkan ke `model.fit`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YPhbu9Tfzd9"
      },
      "source": [
        "#### 3.2.2. TF Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSnpLvhu_Lx2"
      },
      "source": [
        "Tensorflow memiliki satu library terpisah untuk mengelola kumpulan datasets, yakni tensorflow-datasets atau tfds. TFDS memiliki puluhan dataset berbagai bentuk yang siap panggil, dari audio, gambar, sampai teks. Data yang diambil dari TFDS akan langsung berbentuk objek `Datasets` yang dengan mudah kita atur pipelinenya.\n",
        "\n",
        "Kali ini kita akan muat ulang data digit mnist dengan tfds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUMhCXhFXdHQ"
      },
      "source": [
        "mnist = tfds.load('mnist', split=['train[:80%]','train[80%:]','test'], shuffle_files=True, as_supervised=True)\n",
        "mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obeObZUjAECq"
      },
      "source": [
        "Perhatikan bahwa splitting data dapat dengan mudah dilakukan, dan langsung menghasikan 3 data untuk training-validation-test. Selanjutnya kita siapkan pipelinenya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haykx2K9XgiI"
      },
      "source": [
        "def normalize_img(image, label):\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "def create_pipeline(ds, is_shuffle):\n",
        "    ds = ds.map(normalize_img)\n",
        "    ds = ds.cache()\n",
        "    if is_shuffle:\n",
        "        ds = ds.shuffle(1000)\n",
        "    ds = ds.batch(128)\n",
        "    ds = ds.prefetch(1)\n",
        "    return ds\n",
        "\n",
        "ds_train = create_pipeline(mnist[0], True)\n",
        "ds_val = create_pipeline(mnis[1], True)\n",
        "ds_test = create_pipeline(mnist[2], False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBZPLcNlAS1q"
      },
      "source": [
        "Kita pun bisa langsung masukkan ke model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWqxdmS1NLKA"
      },
      "source": [
        "model = build_model()\n",
        "model.fit(ds_train, epochs=2, validation_data=ds_val)\n",
        "model.evaluate(ds_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g69U2eaeHi-u"
      },
      "source": [
        "### 3.3. Custom Training Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGu4gwEpZII9"
      },
      "source": [
        "Proses training di TF bisa didefinisikan secara manual dari awal sampai akhir, tanpa menggunakan metode `fit`. Mula-mula kita definisikan dulu modelnya dengan functional API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaa775ce7dab"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(28,28), name=\"digits\")\n",
        "flat = tf.keras.layers.Flatten()(inputs)\n",
        "x1 = tf.keras.layers.Dense(64, activation=\"relu\")(flat)\n",
        "x2 = tf.keras.layers.Dense(64, activation=\"relu\")(x1)\n",
        "outputs = tf.keras.layers.Dense(10, name=\"predictions\")(x2)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsktBJht8H0-"
      },
      "source": [
        "Selanjutnya, didefinisikan juga optimizer, fungsi loss, dan metric yang digunakan. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2c6257b8d02"
      },
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9tRZNKVA5ty"
      },
      "source": [
        "Kita di sini mengubah data gambar yang ada sebelumnya menjadi TF Datasets dengan pipeline yang sesuai."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT_eqDvzA0E1"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((img_train, lab_train))\n",
        "train_ds = train_ds.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((img_val, lab_val))\n",
        "val_ds = val_ds.batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsUZeqA-AzRt"
      },
      "source": [
        "Saatnya melakukan proses training manual! Perhatikan  langkahnya baik-baik"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "654e2311dbff"
      },
      "source": [
        "# tetapkan jumlah epochs\n",
        "epochs = 3\n",
        "\n",
        "# iterasi setiap epoch\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "    # iterasi setiap batch di training Datasets\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_ds):\n",
        "        # tetapkan scope Gradient Tape untuk merekam proses perhitungan loss\n",
        "        with tf.GradientTape() as tape:\n",
        "            # hitung output dari model\n",
        "            y_out = model(x_batch_train, training=True)\n",
        "            # hitung loss dari output yang dihasilkan\n",
        "            loss_value = loss_fn(y_batch_train, y_out)\n",
        "        # hitung gradient dari perhitungan yang sudah direkam \n",
        "        # terhadap parameter-parameter di dalam modelnya model\n",
        "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "        # minta optimizer untuk update parameter \n",
        "        # berdasarkan gradient yang sudah dihitung\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "        # update metric untuk batch ini\n",
        "        train_acc_metric.update_state(y_batch_train, y_out)\n",
        "        if step % 200 == 0:\n",
        "            print(step, \"steps: \", loss_value.numpy())\n",
        "    # dapatkan akumulasi metric di epoch ini\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "    # lakukan hal yang serupa pada validation Datasets\n",
        "    # perbedaannya hanya kali ini tidak dilakukan update parameter\n",
        "    for x_batch_val, y_batch_val in val_ds:\n",
        "        val_logits = model(x_batch_val, training=False)\n",
        "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_acc_metric.reset_states()\n",
        "    print(\"Validation acc: %.4f\" % (float(val_acc),))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ51sp-prvpD"
      },
      "source": [
        "**That is all!**\n",
        "Tentu saja masih banyak hal di Tensorflow yang belum kebahas di sini, tapi semoga ini bisa jadi awal perjalanan deep learnjng anda ke depan!\n",
        "\n",
        "> Aditya Firman Ihsan\n",
        "\n",
        "![](https://i.pinimg.com/236x/57/88/60/57886048a910db370c961afab837cca1--happy-new-year-atlanta.jpg)"
      ]
    }
  ]
}